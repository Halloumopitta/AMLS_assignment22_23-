{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56fec661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim  \n",
    "import torchvision.transforms as transforms  \n",
    "import torchvision\n",
    "from torch.utils.data import (Dataset,DataLoader) \n",
    "\n",
    "from PIL import Image\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f05a91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas\\Desktop\\ML\\Final\n",
      " cpu being used\n"
     ]
    }
   ],
   "source": [
    "#Get working directory\n",
    "directory = os.getcwd() # Path of the current working directory.\n",
    "print(directory)\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\" {device} being used\")\n",
    "#if cpu is being used with PyTorch training will be slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709de3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "num_epochs = 5 #complete passess over the data set\n",
    "num_classes = 2 #male/female or smile/no-smile\n",
    "batch_size = 100 #data must be loaded in batches for more efficient training (high batch size can lead to memory overload)\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14ca2a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformations on the images\n",
    "#transformer=transforms.Compose([transforms.Resize((224,224)), #make sure all images are the same size\n",
    "#                                transforms.ToPILImage(),\n",
    "#                                transforms.RandomHorizontalFlip(), #0.5 chance for image to be flipped to increase uniqueness x2\n",
    "#                                transforms.ToTensor(),#pixel rate from 0-255 to 0-1 as PyTorch only reads tensors\n",
    "#                                transforms.Normalize([0.5,0.5,0.5], #change range from 0-1 to (-1)-1 for RGB channel\n",
    "#                                                     [0.5,0.5,0.5]) #formula:(x-mean)/std\n",
    "#]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "591baacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to load the custom dataset\n",
    "\n",
    "class celebaDataset(Dataset):\n",
    "    def __init__(self,csv_file,root_dir,transform=None):\n",
    "        self.annotations=pd.read_csv(csv_file)\n",
    "        self.root_dir=root_dir\n",
    "        self.transform=transform\n",
    "        pass\n",
    "  \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.annotations)\n",
    "        pass\n",
    "    def __getitem__(self, index): #PyTorch chooses the index\n",
    "        img_path=os.path.join(self.root_dir, self.annotations.iloc[index,0]) #row 'index' and column 0\n",
    "        image=io.imread(img_path)\n",
    "        y_label=torch.tensor(int(self.annotations.iloc[index,1]))\n",
    "        y=(y_label+1)/2\n",
    "        yt=y.type(torch.LongTensor)\n",
    "        if self.transform:\n",
    "            image=self.transform(image)\n",
    "        return (image,yt)\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a4f005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 5000\n",
      "Test dataset size: 1000\n"
     ]
    }
   ],
   "source": [
    "train_dataset=celebaDataset(csv_file='dataset_AMLS_22-23/celeba/gender_labels.csv',\n",
    "                            root_dir='dataset_AMLS_22-23/celeba/img',transform=transforms.ToTensor())\n",
    "train_loader=DataLoader(dataset=train_dataset,batch_size=100,shuffle=True)\n",
    "#shuffle=True to ensure our model is not biased for some categories \n",
    "test_dataset=celebaDataset(csv_file='dataset_AMLS_22-23_test/celeba_test/gender_labels_test.csv',\n",
    "                            root_dir='dataset_AMLS_22-23_test/celeba_test/img_test',transform=transforms.ToTensor())\n",
    "test_loader=DataLoader(dataset=test_dataset,batch_size=100,shuffle=True)\n",
    "print('Train dataset size:', len(train_dataset)) #must give 5000\n",
    "print('Test dataset size:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a0690a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN model\n",
    "class convNet(nn.Module):\n",
    "    def __init__(self,num_classes=2):\n",
    "        super(convNet,self).__init__()\n",
    "        \n",
    "        #Input shape =(batch_size,RGB_channel,Image dimensions)=(100,3,178,218)\n",
    "        #The first convolutional layer\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #New shape from formula (width-kernel+2P)/s +1 ->Shape=(100,12,178,218)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12) #normalisation\n",
    "        #Shape=(100,12,178,218)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape=(100,12,178,218)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape= (100,12,89,109)\n",
    "        \n",
    "        #second convolutional layer\n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (100,20,89,109)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (100,20,89,109)\n",
    "        \n",
    "        \n",
    "        #Third convolutional layer\n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (100,32,89,109)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape= (100,32,89,109)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (100,32,89,109)\n",
    "        \n",
    "        #fully connected layer\n",
    "        self.fc=nn.Linear(in_features=89 * 109 * 32,out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        #feed forward function\n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "            \n",
    "        #Above output will be in matrix form, with shape (100,32,112,112)\n",
    "            \n",
    "        output=output.view(-1,32*89*109)\n",
    "            \n",
    "            \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84155364",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=convNet(num_classes=2).to(device) #send it to cuda/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c16709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss and optimizer functions\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d4610dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 0 is 0.026011550644616365\n",
      "Cost at epoch 1 is 0.025158186147455127\n",
      "Cost at epoch 2 is 0.005120548393852005\n",
      "Cost at epoch 3 is 0.0016445697624112654\n",
      "Cost at epoch 4 is 0.0018914735615112477\n",
      "Checking accuracy on Training Set\n",
      "Got 5000 / 5000 with accuracy 100.00\n",
      "Checking accuracy on Test Set\n",
      "Got 920 / 1000 with accuracy 92.00\n"
     ]
    }
   ],
   "source": [
    "# Train Network\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")\n",
    "\n",
    "# Check accuracy on training to see how good our model is\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(\n",
    "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
    "        )\n",
    "\n",
    "    model.train()\n",
    "\n",
    "\n",
    "print(\"Checking accuracy on Training Set\")\n",
    "check_accuracy(train_loader, model)\n",
    "    \n",
    "print(\"Checking accuracy on Test Set\")\n",
    "check_accuracy(test_loader, model)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e0461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c67c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
